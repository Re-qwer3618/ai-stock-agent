import streamlit as st
import os

# Pinecone
from pinecone import Pinecone
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_pinecone import PineconeVectorStore

# Gemini (ì§ì ‘ REST ì‚¬ìš©)
import google.generativeai as genai


# =========================
# 1. ì œëª© ë° ê¸°ë³¸ ì„¤ì •
# =========================
st.title("ğŸ§  ë‚˜ë§Œì˜ AI-agent (Pinecone Ver.)")
st.caption("ë¶„ì„ì´ í•„ìš”í•œ ì¢…ëª©ì— ëŒ€í•´ì„œ AIê°€ ë¶„ì„í•´ì¤ë‹ˆë‹¤.")


# =========================
# 2. API í‚¤ ì„¤ì •
# =========================
if "GOOGLE_API_KEY" not in st.secrets or "PINECONE_API_KEY" not in st.secrets:
    st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Secretsë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]

# Gemini ì„¤ì • (REST, ë™ê¸°)
genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
gemini_model = genai.GenerativeModel("gemini-1.5-flash")

# Pinecone ì„¤ì •
pc = Pinecone(api_key=st.secrets["PINECONE_API_KEY"])


# =========================
# 3. Pinecone ì¸ë±ìŠ¤ ì—°ê²°
# =========================
index_name = "ai-stock-agent"  # íŒŒì¸ì½˜ ì½˜ì†”ì— ì‹¤ì œ ì¡´ì¬í•´ì•¼ í•¨

embeddings = GoogleGenerativeAIEmbeddings(
    model="models/embedding-001"
)

# âš ï¸ from_existing_index ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ì˜¤ë¥˜ ì›ì¸)
index = pc.Index(index_name)

vectorstore = PineconeVectorStore(
    index=index,
    embedding=embeddings
)


# =========================
# 4. ì‚¬ì´ë“œë°”: ì¢…ëª© ì¶”ê°€
# =========================
with st.sidebar:
    st.header("ğŸ“ ì¢…ëª© ì¶”ê°€í•˜ê¸°")
    txt_input = st.text_area("ë¶„ì„í•  ì¢…ëª© ë˜ëŠ” ë©”ëª¨ë¥¼ ì…ë ¥í•˜ì„¸ìš”", height=150)

    if st.button("ì¢…ëª© ë¶„ì„ ë°ì´í„° ì €ì¥"):
        if txt_input.strip():
            vectorstore.add_texts([txt_input])
            st.success("Pineconeì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤ ğŸ’¾")
        else:
            st.warning("ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")


# =========================
# 5. ì§ˆë¬¸í•˜ê¸° (RAG)
# =========================
st.header("ğŸ” ì§ˆë¬¸í•˜ê¸°")
query = st.text_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”?")

if st.button("ì§ˆë¬¸ ë³´ë‚´ê¸°"):
    if not query.strip():
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    with st.spinner("ê¸°ì–µì„ ê²€ìƒ‰í•˜ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        # 1ï¸âƒ£ Pineconeì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        docs = vectorstore.similarity_search(query, k=4)

        if not docs:
            st.warning("ì°¸ê³ í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì¢…ëª©ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
            st.stop()

        # 2ï¸âƒ£ Context êµ¬ì„±
        context = "\n\n".join([doc.page_content for doc in docs])

        prompt = f"""
ë„ˆëŠ” ì£¼ì‹ ë¶„ì„ AI ì—ì´ì „íŠ¸ë‹¤.
ì•„ë˜ì˜ ì •ë³´ë¥¼ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ë¼.

[ì°¸ê³  ì •ë³´]
{context}

[ì§ˆë¬¸]
{query}
"""

        # 3ï¸âƒ£ Gemini í˜¸ì¶œ (ë™ê¸° / REST)
        response = gemini_model.generate_content(prompt)

        # =========================
        # 6. ê²°ê³¼ ì¶œë ¥
        # =========================
        st.subheader("ğŸ¤– AIì˜ ë‹µë³€")
        st.write(response.text)

        with st.expander("ğŸ“š ì°¸ê³ í•œ ì†ŒìŠ¤ ë³´ê¸°"):
            for i, doc in enumerate(docs, start=1):
                st.write(f"{i}. {doc.page_content}")
