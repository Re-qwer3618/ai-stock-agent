import streamlit as st
import os
from pinecone import Pinecone
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains.retrieval_qa.base import RetrievalQA


# 1. ì œëª© ë° ì„¤ì •
st.title("ğŸ§  ë‚˜ë§Œì˜ ì„¸ì»¨ë“œ ë¸Œë ˆì¸ (Pinecone Ver.)")
st.caption("ê¸°ì–µí•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì…ë ¥í•˜ë©´, AIê°€ ê¸°ì–µí–ˆë‹¤ê°€ ëŒ€ë‹µí•´ì¤ë‹ˆë‹¤.")

# 2. API í‚¤ ì„¤ì • (ìŠ¤íŠ¸ë¦¼ë¦¿ í´ë¼ìš°ë“œ ë¹„ë°€ë³´ê´€ì†Œì—ì„œ ê°€ì ¸ì˜´)
# ë¡œì»¬ì—ì„œ í…ŒìŠ¤íŠ¸í•  ë• ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆìœ¼ë‹ˆ ë°°í¬ í›„ ì‘ë™ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
if "GOOGLE_API_KEY" in st.secrets and "PINECONE_API_KEY" in st.secrets:
    os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]
    pc = Pinecone(api_key=st.secrets["PINECONE_API_KEY"])
else:
    st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Secretsë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# 3. Pinecone ì¸ë±ìŠ¤ ì—°ê²°
index_name = "second-brain" # íŒŒì¸ì½˜ í™ˆí˜ì´ì§€ì—ì„œ ë§Œë“  ì´ë¦„ê³¼ ê°™ì•„ì•¼ í•¨!
embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")

# ë²¡í„° ì €ì¥ì†Œ ì—°ê²°
vectorstore = PineconeVectorStore.from_existing_index(
    index_name=index_name,
    embedding=embeddings
)


# 4. ì‚¬ì´ë“œë°”: ê¸°ì–µ ì…ë ¥í•˜ê¸°
with st.sidebar:
    st.header("ğŸ“ ê¸°ì–µ ì¶”ê°€í•˜ê¸°")
    txt_input = st.text_area("ê¸°ì–µí•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”", height=150)
    if st.button("ê¸°ì–µí•˜ê¸°"):
        if txt_input:
            # í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•´ì„œ Pineconeì— ì €ì¥ (Upsert)
            vectorstore.add_texts([txt_input])
            st.success("ì„±ê³µì ìœ¼ë¡œ ê¸°ì–µí–ˆìŠµë‹ˆë‹¤! ğŸ’¾")
        else:
            st.warning("ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# 5. ë©”ì¸ í™”ë©´: ì§ˆë¬¸í•˜ê¸°
st.header("ğŸ” ì§ˆë¬¸í•˜ê¸°")
query = st.text_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”?")

if st.button("ì§ˆë¬¸ ë³´ë‚´ê¸°"):
    if query:
        with st.spinner("ê¸°ì–µì„ ë’¤ì§€ëŠ” ì¤‘..."):
            llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0)
            
            # RAG ì²´ì¸ ìƒì„± (ê²€ìƒ‰ -> ë‹µë³€)
            qa_chain = RetrievalQA.from_chain_type(
                llm=llm,
                chain_type="stuff",
                retriever=vectorstore.as_retriever(),
                return_source_documents=True
            )
            
            result = qa_chain.invoke({"query": query})
            st.write("ğŸ¤– **AIì˜ ë‹µë³€:**")
            st.write(result["result"])
            
            # ê·¼ê±° ìë£Œ ë³´ì—¬ì£¼ê¸° (ì˜µì…˜)
            with st.expander("ì°¸ê³ í•œ ê¸°ì–µ ë³´ê¸°"):
                for doc in result["source_documents"]:
                    st.write(f"- {doc.page_content}")