import os
import json
import pandas as pd
import time
from tqdm import tqdm  # ì§„í–‰ë¥  í‘œì‹œë°”
from pinecone import Pinecone, ServerlessSpec
from langchain_google_genai import GoogleGenerativeAIEmbeddings
import streamlit as st

# ==========================================
# 1. ì„¤ì • (API í‚¤ ë° í™˜ê²½)
# ==========================================
# Streamlit Cloud ë°°í¬ìš© (Secrets ì‚¬ìš©)
if hasattr(st, "secrets"):
    if "GOOGLE_API_KEY" in st.secrets:
        os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]
    if "PINECONE_API_KEY" in st.secrets:
        os.environ["PINECONE_API_KEY"] = st.secrets["PINECONE_API_KEY"]

# ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© (ì§ì ‘ ì…ë ¥ í•„ìš”ì‹œ ì£¼ì„ í•´ì œ í›„ ì…ë ¥)
# os.environ["GOOGLE_API_KEY"] = "ì—¬ê¸°ì—_êµ¬ê¸€_APIí‚¤"
# os.environ["PINECONE_API_KEY"] = "ì—¬ê¸°ì—_íŒŒì¸ì½˜_APIí‚¤"

# ì¸ë±ìŠ¤ ì´ë¦„ (app.pyì™€ ë™ì¼í•´ì•¼ í•¨)
INDEX_NAME = "ai-stock-agent"

# ==========================================
# 2. ì´ˆê¸°í™” (ëª¨ë¸ & DB ì—°ê²°)
# ==========================================
print("ğŸ”Œ Pinecone ë° Gemini ëª¨ë¸ ì—°ê²° ì¤‘...")
try:
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    pc = Pinecone(api_key=os.environ["PINECONE_API_KEY"])
    index = pc.Index(INDEX_NAME)
    print("âœ… ì—°ê²° ì„±ê³µ!")
except Exception as e:
    print(f"âŒ ì—°ê²° ì‹¤íŒ¨: {e}")
    print("API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit()

# ==========================================
# 3. ë°ì´í„° ë¡œë”© ë° ì²˜ë¦¬ í•¨ìˆ˜
# ==========================================
def process_csv(file_path):
    """CSV íŒŒì¼ì„ ì½ì–´ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    data = []
    try:
        df = pd.read_csv(file_path)
        print(f"ğŸ“‚ CSV ë¡œë”©: {len(df)}í–‰ ë°œê²¬ ({file_path})")
        
        for idx, row in df.iterrows():
            # ê° ì»¬ëŸ¼ì˜ ì´ë¦„ê³¼ ê°’ì„ í•©ì³ì„œ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ ë§Œë“¦
            # ì˜ˆ: "Date: 2024-01-01, Name: ì‚¼ì„±ì „ì, Close: 70000"
            text_chunks = [f"{col}: {val}" for col, val in row.items()]
            text = ", ".join(text_chunks)
            data.append({"id": f"csv-{idx}", "text": text})
            
    except Exception as e:
        print(f"âš ï¸ CSV ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    return data

def process_jsonl(file_path):
    """JSONL íŒŒì¼ì„ ì½ì–´ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    data = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            print(f"ğŸ“‚ JSONL ë¡œë”©: {len(lines)}í–‰ ë°œê²¬ ({file_path})")
            
            for idx, line in enumerate(lines):
                if not line.strip(): continue
                json_obj = json.loads(line)
                # JSON ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                text = json.dumps(json_obj, ensure_ascii=False)
                data.append({"id": f"jsonl-{idx}", "text": text})
                
    except Exception as e:
        print(f"âš ï¸ JSONL ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    return data

# ==========================================
# 4. ë©”ì¸ ì‹¤í–‰ (ì—…ë¡œë“œ ë¡œì§)
# ==========================================
def main():
    all_data = []
    
    # 1) íŒŒì¼ ì½ê¸°
    if os.path.exists("Etc_V1.csv"):
        all_data.extend(process_csv("Etc_V1.csv"))
    else:
        print("âš ï¸ Etc_V1.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    if os.path.exists("Etc_V1.jsonl"):
        all_data.extend(process_jsonl("Etc_V1.jsonl"))
    else:
        print("âš ï¸ Etc_V1.jsonl íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    if not all_data:
        print("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ìœ„ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    print(f"\nğŸš€ ì´ {len(all_data)}ê°œì˜ ë°ì´í„°ë¥¼ Pineconeì— ì—…ë¡œë“œí•©ë‹ˆë‹¤...")
    
    # 2) ë°°ì¹˜ ì—…ë¡œë“œ (100ê°œì”© ëŠì–´ì„œ ì „ì†¡ - ì•ˆì •ì„± í™•ë³´)
    batch_size = 100
    
    for i in tqdm(range(0, len(all_data), batch_size), desc="ì—…ë¡œë“œ ì§„í–‰ë¥ "):
        batch = all_data[i : i + batch_size]
        vectors = []
        
        for item in batch:
            try:
                # í…ìŠ¤íŠ¸ -> ë²¡í„° ë³€í™˜ (Embedding)
                vector_values = embeddings.embed_query(item['text'])
                
                vectors.append({
                    "id": item['id'],
                    "values": vector_values,
                    "metadata": {"text": item['text']}
                })
            except Exception as e:
                print(f"âš ï¸ ë³€í™˜ ì‹¤íŒ¨ (ID: {item['id']}): {e}")
                continue
        
        # Pineconeì— ì €ì¥ (Upsert)
        if vectors:
            index.upsert(vectors=vectors)
            
    print("\nğŸ‰ ëª¨ë“  ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ! ì´ì œ app.pyì—ì„œ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()